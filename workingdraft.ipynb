{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect Data: Capture and label images of our handwriting.\n",
    "    [ ] Chelsey\n",
    "    [ ] Shawn\n",
    "    [ ] Starter data set (MNIST)\n",
    "\n",
    "Preprocess Data: Resize, normalize, and encode the images and labels.\n",
    "\n",
    "Build a CNN Model: Use Keras to define a CNN suitable for image classification.\n",
    "Train the Model: Fit the model on your handwriting dataset.\n",
    "Evaluate and Predict: Assess model accuracy and use it to predict new handwriting samples.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# LabelBinarizer during training\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train)  # Fit the LabelBinarizer with the labels\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "with open(\"label_binarizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lb, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shawn\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a simple neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the 2D image into a 1D vector\n",
    "    layers.Dense(128, activation='relu'),  # First dense layer with 128 neurons and ReLU activation\n",
    "    layers.Dropout(0.2),                   # Dropout layer to prevent overfitting\n",
    "    layers.Dense(10, activation='softmax') # Output layer with 10 classes and softmax activation\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.5418 - val_accuracy: 0.9551 - val_loss: 0.1604\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.1700 - val_accuracy: 0.9653 - val_loss: 0.1185\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.1187 - val_accuracy: 0.9693 - val_loss: 0.1011\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0937 - val_accuracy: 0.9723 - val_loss: 0.0937\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.0793 - val_accuracy: 0.9743 - val_loss: 0.0875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fd277cef50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 2ms/step - accuracy: 0.9766 - loss: 0.0776\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed image (partial): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Image shape before prediction: (28, 28)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Prediction output: [[2.1623563e-26 3.9906134e-12 6.2794352e-06 3.6717242e-01 3.7656715e-37\n",
      "  6.3282120e-01 3.8766984e-08 1.0420770e-15 6.3793912e-08 7.3396906e-28]]\n",
      "Predicted Label: 5\n"
     ]
    }
   ],
   "source": [
    "with open(\"label_binarizer.pkl\", \"rb\") as f:\n",
    "    lb = pickle.load(f)\n",
    "\n",
    "# Define preprocess_image function here\n",
    "def preprocess_image(image_path, img_size=(28, 28)):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, img_size)\n",
    "    image = image / 255.0  # Normalize the image\n",
    "    \n",
    "    # Debugging step: print a portion of the preprocessed image\n",
    "    print(f\"Preprocessed image (partial): {image.flatten()[:10]}\")  # Print the first 10 pixel values\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Define predict_handwriting function here\n",
    "def predict_handwriting(image_path, model, lb, img_size=(28, 28)):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path, img_size)\n",
    "    print(f\"Image shape before prediction: {image.shape}\")  # Debugging step\n",
    "    image = image.reshape(1, img_size[0], img_size[1], 1)\n",
    "    \n",
    "    # Predict the class\n",
    "    prediction = model.predict(image)\n",
    "    print(f\"Prediction output: {prediction}\")  # Debugging step\n",
    "    predicted_label = lb.inverse_transform(prediction)[0]\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Example usage with your model\n",
    "image_path = \"Resources/Test Images/number4.png\"\n",
    "predicted_label = predict_handwriting(image_path, model, lb)\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
